{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm Project Using Kaggle Datasets\n",
    "\n",
    "dataset url : https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification?select=test\n",
    "\n",
    "### Task : Using Image Classification for Distinguishing Muffin and Chihuahua\n",
    "\n",
    "* The goal of the project is to create a model that uses SVC and CNN supervised learning to distinguish between muffins and chihuahua.\n",
    "* 이 프로젝트의 목표는 SVC와 CNN 지도학습을 이용하여 머핀과 치와와를 구분할 수 있는 모델을 만드는 것 입니다.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/2SXNWP7f/muffin-meme2.jpg\"  width=\"50%\" height=\"50%\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터셋 설명\n",
    "* 모든 데이터 셋은 muffin과 chihuahua 단어에 대해 구글 이미지 결과값을 스크랩한 바이너리 이미지 파일로 구성되어있습니다.\n",
    "\n",
    "* 선택한 데이터 셋은 아래와 같은 두 가지의 데이터 셋으로 나뉘어있습니다.\n",
    "    * train\n",
    "    * test\n",
    "    * 각각의 데이터 셋 내부에는 두 가지의 레이블이 존재합니다.\n",
    "        * muffin\n",
    "        * chihuahua\n",
    "        \n",
    "* 모델 학습 시 데이터 셋은 다음과 같이 분류하여 사용하였습니다.\n",
    "    * train data : 학습 데이터 (3733장의 이미지)\n",
    "    * validation data : 모델 성능 검증을 위한 데이터 (1000장의 이미지)\n",
    "    * train data : 모델 학습 종료 후 모델을 테스트하기 위한 데이터 (1184장의 이미지)\n",
    "\n",
    "\n",
    "### Dataset Description\n",
    "* All datasets consist of binary image files obtained by scraping Google Image search results for the words \"muffin\" and \"chihuahua.\"\n",
    "\n",
    "* The selected dataset is divided into two main datasets:\n",
    "    * Train\n",
    "    * Test\n",
    "    * Each dataset contains two labels:\n",
    "        * Muffin\n",
    "        * Chihuahua\n",
    "* During model training, the datasets were categorized as follows:\n",
    "    * Train Data: Used for model training (3733 images)\n",
    "    * Validation Data: Used for model performance validation (1000 images)\n",
    "    * Test Data: Used to test the model after training completion (1184 images)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 및 테스트 환경\n",
    "\n",
    "* 구글 Colab에서 T4GPU를 사용하여 모델 학습 및 테스트 진행.\n",
    "\n",
    "### 이미지 분류를 위해 선택한 지도학습 알고리즘\n",
    "\n",
    "1. SVC(Support Vector Machine with a Linear Kernel)\n",
    "    * SVM은 주어진 데이터들을 분류하는 가장 최적의 결정 경계를 찾는 알고리즘입니다.\n",
    "        * SVC는 SVM을 이용하여 분류 작업 시, 선형 커널을 적용한 지도학습 알고리즘입니다.\n",
    "2. CNN (Convolutional Neural Network)\n",
    "    * 입력된 이미지에 대해 필터(커널)를 사용하여 이미지의 특징을 추출하고, 학습하는 알고리즘입니다.\n",
    "    * 이미지에 대해 먼저 커널과 합성곱(Convolutional Layers)이 이루어지고, 이후에는 Pooling Layer를 거쳐 가장 특징적인 정보를 추출합니다.\n",
    "    * 특징 정보들은 다층 퍼셉트론(MLP)을 통해 분류 작업에 사용됩니다.\n",
    "\n",
    "### Model Training and Testing Environment\n",
    "\n",
    "* Model training and testing were conducted using T4 GPU on Google Colab.\n",
    "\n",
    "### Supervised Learning Algorithms Chosen for Image Classification\n",
    "\n",
    "1. SVC (Support Vector Machine with a Linear Kernel)\n",
    "    * SVM is an algorithm that finds the optimal boundary for classifying given data.\n",
    "        * SVC is a supervised learning algorithm that applies a linear kernel to classify data using SVM.\n",
    "2. CNN (Convolutional Neural Network)\n",
    "    * It is an algorithm that extracts and learns features of an image using filters (kernels).\n",
    "    * For images, convolutional layers are applied to the images first, followed by a pooling layer to extract the most distinctive information.\n",
    "    * The feature information is then used for classification tasks via a multi-layer perceptron (MLP).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SVC (Support Vector Machine with a Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 필요한 라이브러리 import - Importing Essential Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Colab 환경에 데이터 저장 (kaggle API 사용) - Installing Kaggle API and Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d samuelcortinhas/muffin-vs-chihuahua-image-classification\n",
    "!unzip  muffin-vs-chihuahua-image-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 학습 관련 변수 사전 설정 - Setting up training-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/content/train'          # 이미지를 가져올 디렉토리 위치\n",
    "CATEGORIES = ['chihuahua','muffin'] # 이미지를 구분할 카테고리\n",
    "IMG_SIZE=100                        # 데이터 전처리 시 정규화할 이미지 크기 지정\n",
    "\n",
    "# 학습시킬 이미지 목록을 저장할 리스트\n",
    "training_data=[]\n",
    "# 학습시킬 이미지의 이미지 데이터를 저장할 리스트\n",
    "X=[]\n",
    "# 학습시킬 이미지의 레이블 데이터를 저장할 리스트\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. 훈련 데이터 생성 - Create train dataset\n",
    "\n",
    "* 'chihuahua'와 'muffin' 범주에서 이미지 데이터를 읽어들이고, 크기를 조정한 후 'training_data' 리스트에 [이미지, 레이블] 형식으로 저장합니다. 'class_num' 변수는 레이블을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "     \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. 데이터 전처리 - Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenofimage = len(training_data)\n",
    "\n",
    "# 'X' 리스트에 이미지 데이터를 저장하고, \n",
    "# 'y' 리스트에 레이블 데이터를 저장합니다.\n",
    "for categories, label in training_data:\n",
    "    X.append(categories)\n",
    "    y.append(label)\n",
    "\n",
    "# 'X'와 'y' 데이터를 NumPy 배열로 변환하고, 이미지 데이터를 0-1 범위로 정규화합니다.\n",
    "X= np.array(X).reshape(lenofimage,-1)\n",
    "# 배열을 단순화 합니다. 예) [1,2,[3,4,[5,6,]]] => [1,2,3,4,5,6]\n",
    "X = X/255.0\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. 데이터 분할 - Split train data to train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y) # 학습시킬 데이터와 학습 후 테스트할 데이터로 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. 모델 로드 후 학습 진행 - Load SVC model and Perform Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear',gamma='auto') # 커널은 선형 커널을 사용하고, 감마 값은 자동으로 계산되도록 합니다.\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8. 학습된 결과를 이용하여 모델 테스트 후 결과 출력 - Test Trained Model and Get the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = svc.predict(X_test)\n",
    "\n",
    "# 모델의 정확도 계산 - Calculate Model's Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on data is\",accuracy_score(y_test,y2))\n",
    "\n",
    "# 세부적인 Test 결과 출력 - Get Detail Test Result\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy on data is\",classification_report(y_test,y2))\n",
    "\n",
    "# test 로그 출력 (0: 치와와, 1: 머핀)\n",
    "result = pd.DataFrame({'original' : y_test,'predicted' : y2})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8.1 출력된 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy on data is 0.6942567567567568\n",
    "\n",
    "Accuracy on         data is              precision     recall   f1-score   support\n",
    "\n",
    "                                            0           0.69      0.80      0.74       640\n",
    "                                            1           0.70      0.58      0.63       544\n",
    "\n",
    "                            accuracy                                        0.69      1184\n",
    "                            macro avg                   0.70      0.69      0.69      1184\n",
    "                            weighted avg                0.70      0.69      0.69      1184\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"./Images/5555.PNG\"  width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 필요한 라이브러리 import - Importing Essential Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Colab 환경에 데이터 저장 (kaggle API 사용) - Installing Kaggle API and Data Download : 1.2 항목과 동일한 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. 학습 관련 변수 사전 설정 - Setting up training-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # 학습률\n",
    "batch_size = 100 # 한번에 얼만큼의 이미지를 학습시킬지\n",
    "epochs = 10 # 데이터를 몇 번 반복하여 학습시킬지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 데이터 전처리 - Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지 데이터를 일괄적으로 300 * 300 의 크기로 정규화하고, \n",
    "# 텐서로 변환되도록 데이터 전처리 파이프라인을 정의합니다.\n",
    "trans = transforms.Compose([transforms.Resize((300, 300)),\n",
    "                           transforms.ToTensor()\n",
    "                           ])\n",
    "\n",
    "# 각 이미지 폴더에 위치한 이미지들을 정규화한 데이터셋으로 가져옵니다.\n",
    "train_dataset = torchvision.datasets.ImageFolder(root= '/content/train',\n",
    "                                                     transform = trans)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root= '/content/test',\n",
    "                                                     transform = trans)\n",
    "\n",
    "# train 데이터를 train / validation 데이터가 랜덤한 두 가지 값으로 나뉘도록 합니다.\n",
    "val_size = 1000\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_data,val_data = random_split(train_dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "# 각 학습용 데이터들을 사전 정의한 batch_size 단위로 처리할 수 있도록 데이터 로드를 생성합니다.\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "print(len(train_data), len(train_loader))\n",
    "print(len(val_data), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 CNN 모델 정의 - CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn,self).__init__()\n",
    "\n",
    "        # 첫번째 레이어 정의\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 이미지를 입력값으로 받으므로, 최초 입력 채널의 크기는 3입니다.(RGB)\n",
    "            # CNN에서 가장 기본적으로 사용되는 3*3 크기의 커널을 필터로 선택합니다.\n",
    "            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n",
    "            # BatchNorm2d를 이용하여 학습 시 사용되는 batch를 정규화합니다.\n",
    "            # 정규화 과정을 통해 학습을 더 안정적으로 진행할 수 있습니다.\n",
    "            nn.BatchNorm2d(16),\n",
    "            # 활성화 함수로는 Relu를 사용합니다.\n",
    "            nn.ReLU(),\n",
    "            # 2x2 Max 풀링을 수행하여 가장 큰 특징을 추출합니다.\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # 두번째 레이어 정의\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        # 세번째 레이어 정의\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # MLP 레이어 정의\n",
    "        # 출력된 최종 레이어를 하나로 쭉 늘어뜨린 뒤, 10개의 출력층에 맵핑합니다.\n",
    "        self.fc1 = nn.Linear(1296,10)\n",
    "        # Dropout 레이어는 학습 중 일부 뉴런을 무작위로 비활성화하여 과적합을 방지합니다.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # 위에서 10개로 줄어든 출력층을 최종 muffin/chihuahua 2개의 출력층으로 분류합니다.\n",
    "        self.fc2 = nn.Linear(10,2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    # 상단에서 정의해준 각각의 레이어를 실행시키는 순방향전파 기능을 정의합니다.\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 모델 학습 준비 - Prepare for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 : 상단에서 정의한 모델 활용\n",
    "model = Cnn().cuda()\n",
    "# 모델 학습 모드 설정\n",
    "model.train()\n",
    "# 최적화 함수 설정 : Adam(Adaptive Moment Estimation)\n",
    "# Adam? : Pytorch에 구현되어있는 경사하강법의 변형 중 하나\n",
    "optimizer = optim.Adam(params = model.parameters(),lr=0.001)\n",
    "# 손실 함수는 CrossEntropy함수를 사용합니다.\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. 모델 학습 수행 - Perform Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    # 학습 데이터 로더 train_loader에서 batch 데이터를 가져옵니다.\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        output = model(batch_images)\n",
    "        loss = criterion(output, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()   # 최적화 함수 가중치 초기화\n",
    "        loss.backward()         # 역전파 수행하여 가중치 계산하고, 모델의 파라미터를 업데이트\n",
    "        optimizer.step()        # 최적화 함수의 파라미터도 업데이트\n",
    "\n",
    "        acc = ((output.argmax(dim=1) == batch_labels).float().mean())   # 예측값의 정확도를 계산합니다.\n",
    "        epoch_accuracy += acc/len(train_loader)                         # 지금 수행중인 학습의 정확도와 손실을 누적합니다.\n",
    "        epoch_loss += loss/len(train_loader)\n",
    "\n",
    "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n",
    "\n",
    "\n",
    "    with torch.no_grad():       # validation data로 학습에 대한 검증을 수행합니다.\n",
    "        epoch_val_accuracy=0\n",
    "        epoch_val_loss =0\n",
    "        for data, label in val_loader:\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output,label)\n",
    "\n",
    "\n",
    "            acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
    "            epoch_val_accuracy += acc/ len(val_loader)\n",
    "            epoch_val_loss += val_loss/ len(val_loader)\n",
    "\n",
    "        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7.1 출력 확인\n",
    "\n",
    "```\n",
    "Epoch : 1, train accuracy : 0.8281340003013611, train loss : 0.4042232036590576\n",
    "Epoch : 1, val_accuracy : 0.8700001239776611, val_loss : 0.31266215443611145\n",
    "Epoch : 2, train accuracy : 0.8902550935745239, train loss : 0.27626872062683105\n",
    "Epoch : 2, val_accuracy : 0.8899999856948853, val_loss : 0.2872754633426666\n",
    "Epoch : 3, train accuracy : 0.9102311134338379, train loss : 0.2230011373758316\n",
    "Epoch : 3, val_accuracy : 0.9120000004768372, val_loss : 0.2264741063117981\n",
    "Epoch : 4, train accuracy : 0.9289393424987793, train loss : 0.18602629005908966\n",
    "Epoch : 4, val_accuracy : 0.9070000648498535, val_loss : 0.2519312798976898\n",
    "Epoch : 5, train accuracy : 0.9378626942634583, train loss : 0.1698230803012848\n",
    "Epoch : 5, val_accuracy : 0.9110000133514404, val_loss : 0.23171471059322357\n",
    "Epoch : 6, train accuracy : 0.9478866457939148, train loss : 0.14132191240787506\n",
    "Epoch : 6, val_accuracy : 0.9110000133514404, val_loss : 0.2093384712934494\n",
    "Epoch : 7, train accuracy : 0.9589393138885498, train loss : 0.11629442870616913\n",
    "Epoch : 7, val_accuracy : 0.9200000762939453, val_loss : 0.21673990786075592\n",
    "Epoch : 8, train accuracy : 0.9639395475387573, train loss : 0.10555274784564972\n",
    "Epoch : 8, val_accuracy : 0.9149999618530273, val_loss : 0.21225492656230927\n",
    "Epoch : 9, train accuracy : 0.9802554845809937, train loss : 0.07289625704288483\n",
    "Epoch : 9, val_accuracy : 0.9070000052452087, val_loss : 0.2515607476234436\n",
    "Epoch : 10, train accuracy : 0.973684549331665, train loss : 0.07742644846439362\n",
    "Epoch : 10, val_accuracy : 0.9120000004768372, val_loss : 0.24639680981636047\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. 학습 결과 테스트 - Test Model\n",
    "\n",
    "* 학습한 모델을 evaluation 모드로 설정한 후, 테스트용 사진 목록 중 랜덤한 사진을 뽑아 실제 라벨값과 모델이 예측한 라벨값을 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 테스트 데이터셋에서 무작위 이미지 선택\n",
    "random_image_idx = random.randint(0, len(test_data) - 1)\n",
    "image, label = test_data[random_image_idx]\n",
    "\n",
    "# 순방향전파를 실행하여 예측 획득\n",
    "with torch.no_grad():\n",
    "    image = image.unsqueeze(0).cuda()\n",
    "    prediction = model(image)\n",
    "\n",
    "predicted_class = prediction.argmax().item()\n",
    "\n",
    "# 클래스 레이블 목록 정의 (데이터셋에 따라 사용자 정의 가능)\n",
    "class_labels =['chihuahua', 'muffin']\n",
    "\n",
    "# 이미지와 예측을 표시\n",
    "plt.imshow(image.squeeze(0).cpu().permute(1, 2, 0))\n",
    "plt.title(f'Actual: {class_labels[label]}, Predicted: {class_labels[predicted_class]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8.1. 출력 확인\n",
    "\n",
    "<img src=\"./Images/1111.PNG\"  width=\"50%\" height=\"50%\"></img>\n",
    "<img src=\"./Images/2222.PNG\"  width=\"50%\" height=\"50%\"></img>\n",
    "<img src=\"./Images/3333.PNG\"  width=\"50%\" height=\"50%\"></img>\n",
    "<img src=\"./Images/4444.PNG\"  width=\"50%\" height=\"50%\"></img>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
